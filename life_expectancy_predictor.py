# -*- coding: utf-8 -*-
"""Life Expectancy Predictor

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/12RlBajO3gbRnhUjDTCw7GSQeY2JsF711

Data Cleaning
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, RandomizedSearchCV
from sklearn.preprocessing import OneHotEncoder
from sklearn.ensemble import RandomForestClassifier
from scipy.stats import randint

# Load dataset
dataset = pd.read_csv('Religious_Practice_Survival_Data.csv')
dataset['died_2_year'] = dataset['died_2_year'].replace({'Yes': 1, 'No': 0})

#Drop undesired features
dataset = dataset.drop(['agecat', 'hospitalstay_days'], axis = 1)

# Separate the dataset into numerical and categorical features
numerical_features = dataset.select_dtypes(include=['int64', 'float64']).columns
categorical_features = dataset.select_dtypes(exclude=['int64', 'float64']).columns

# Use median imputation on the numerical features for missing values
dataset[numerical_features] = dataset[numerical_features].fillna(dataset[numerical_features].median())

# Use mode imputation on the categorical features for missing values
for col in categorical_features:
    dataset[col] = dataset[col].fillna(dataset[col].mode().iloc[0])

# One-hot encode categorical features
encoder = OneHotEncoder(drop='first', sparse=False)  # Drop first category to avoid dummy variable trap
encoded_categorical = encoder.fit_transform(dataset[categorical_features])
# Create DataFrame from encoded categorical features
encoded_categorical_df = pd.DataFrame(encoded_categorical, columns=encoder.get_feature_names_out(categorical_features))

# Combine numerical and encoded categorical features into X
X = pd.concat([dataset[numerical_features], encoded_categorical_df], axis=1)
# Define target variable y
y = dataset['died_2_year']

"""RandomForest Classifier and Metric Evaluation"""

# Split data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

param_dist = {
    'n_estimators': randint(50,100),
    'max_depth': randint(3,7),
    'min_samples_leaf': randint(5,20),
    'min_samples_split': randint(5,20),
}

random_search = RandomizedSearchCV(estimator=RandomForestClassifier(random_state=42),
                                   param_distributions=param_dist,
                                   n_iter=20,  # Number of parameter settings that are sampled
                                   cv=5,
                                   random_state=42,
                                   scoring='accuracy',
                                   n_jobs=-1)

random_search.fit(X_train, y_train)
best_params = random_search.best_params_
print("Best parameters: ", best_params)
best_rfc = random_search.best_estimator_
best_rfc.fit(X_train, y_train)

# Obtain accuracy
train_score = np.mean(cross_val_score(best_rfc, X_train, y_train, cv=5))
test_score = best_rfc.score(X_test, y_test)
print("Train Score:", train_score)
print("Test Score:", test_score)

from sklearn.metrics import classification_report

y_pred = best_rfc.predict(X_test)
print(classification_report(y_test, y_pred, digits = 5))

"""Evaluation Visualization"""

#Displays a bar plot of any desired input in the column
def target_dist(df, colname):
  if colname not in df.columns:
    print("Column did not exist in DataFrame")
    return
  values = df[colname].value_counts()
  #Plot it
  plt.figure()
  values.plot(kind='bar')
  plt.title(f"Distribution of {colname}")
  plt.xlabel(colname)
  plt.ylabel("Count")
  plt.show()

target_dist(dataset, 'education')

#Display a feature importance of each column in predicting y
feature_importance = best_rfc.feature_importances_
feature_names = X_train.columns

#Plot
plt.figure(figsize=(15,15))
plt.barh(feature_names, feature_importance)
plt.title("Feature Importances")
plt.xlabel("Importance")
plt.ylabel("Feature")
plt.show()

from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
#Create the confusion matrix
cm = confusion_matrix(y_test, y_pred)
disp = ConfusionMatrixDisplay(confusion_matrix=cm)
disp.plot()
plt.title("Confusion matrix")
plt.show()

from sklearn.metrics import roc_curve, roc_auc_score
#Create ROC Curve
y_proba = best_rfc.predict_proba(X_test)[:,1]
fpr, tpr, thresholds = roc_curve(y_test, y_proba)
roc_auc = roc_auc_score(y_test, y_proba)

plt.figure()
plt.plot(fpr, tpr, label=f'AUC={roc_auc:.2f}')
plt.plot([0,1],[0,1], 'k--') #Diagonal line
plt.title('ROC Curve')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.legend(loc='best')
plt.show()

"""Comparing Different Models

Neural Networks
"""

import tensorflow as tf

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state = 42)
model = tf.keras.models.Sequential()
model.add(tf.keras.layers.Dense(256, input_shape=X_train.shape[1:], activation = 'sigmoid'))
model.add(tf.keras.layers.Dense(256, activation='sigmoid'))
model.add(tf.keras.layers.Dense(1, activation='sigmoid'))

model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

model.fit(X_train, y_train, epochs=100)

model.evaluate(X_test, y_test)

"""Gradient Boosting Machine"""

import xgboost as xgb
from sklearn.metrics import accuracy_score
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state = 42)

model = xgb.XGBClassifier(random_state=42)
#Initialize XGBoost Classifier
param_grid = {
    'n_estimators': [50, 100],  # Number of boosting rounds (trees)
    'max_depth': [3, 5, 7],            # Maximum depth of each tree
    'learning_rate': [0.01, 0.1, 0.3], # Step size shrinkage
    'subsample': [0.6, 0.8, 1.0],      # Fraction of samples used for training each tree
    'colsample_bytree': [0.6, 0.8, 1.0],# Fraction of features used for training each tree
    'reg_alpha': [0.1, 0.5],    # L1 regularization term
    'reg_lambda': [0.1, 0.5]    # L2 regularization term
}

# Initialize RandomizedSearchCV
random_search = RandomizedSearchCV(model, param_distributions=param_grid, n_iter=20,
                                   scoring='accuracy', cv=5, verbose=1, random_state=42)
#Perform search
random_search.fit(X_train, y_train)

#Print out results
print("Best parameters: ", random_search.best_params_)
print("Best score: ", random_search.best_score_)

#Get the best_estimators
best_gbm = random_search.best_estimator_

#Make predictions
y_pred = best_gbm.predict(X_test)
gbm_accuracy = accuracy_score(y_test, y_pred)
print("GBM Accuracy:", gbm_accuracy)

"""Logistic Regression"""

from sklearn.linear_model import LogisticRegression
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)

lr = LogisticRegression(C=3, penalty = 'l2', solver = 'liblinear', max_iter = 200)

lr.fit(X_train, y_train)

y_pred = lr.predict(X_test)
lr_accuracy = accuracy_score(y_test, y_pred)
print("Accuracy: {:.5f}".format(lr_accuracy))

"""Support Vector Machine"""

from sklearn.svm import SVC
from sklearn.metrics import accuracy_score
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)

svc = SVC(C = 1, kernel = 'linear', gamma = 'scale', verbose = 1, random_state=42)

svc.fit(X_train, y_train)


y_pred = svc.predict(X_test)
svc_accuracy = accuracy_score(y_test, y_pred)
print("Accuracy: ", svc_accuracy)